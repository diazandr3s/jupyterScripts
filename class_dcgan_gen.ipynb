{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.snapshot_save_iterations=100000\n",
      "self.image_save_iterations=50000\n",
      "self.image_display_iterations=2\n",
      "self.display=1\n",
      "self.snapshot_prefix='/home/outputs/'\n",
      "self.hyperparameters={'trainer': 'COCOGANTrainer', 'lr': 0.0001, 'll_direct_link_w': 100, 'kl_direct_link_w': 0.1, 'll_cycle_link_w': 100, 'kl_cycle_link_w': 0.1, 'gan_w': 10, 'batch_size': 1, 'max_iterations': 4, 'gen': {'name': 'COCOResGen2', 'ch': 64, 'input_dim_a': 3, 'input_dim_b': 3, 'n_enc_front_blk': 3, 'n_enc_res_blk': 3, 'n_enc_shared_blk': 1, 'n_gen_shared_blk': 1, 'n_gen_res_blk': 3, 'n_gen_front_blk': 3}, 'dis': {'name': 'COCOSharedDis', 'ch': 64, 'input_dim_a': 3, 'input_dim_b': 3, 'n_front_layer': 2, 'n_shared_layer': 4}, 'dcgan': {'root_data': './images/data/*', 'image_height': 248, 'image_width': 248, 'num_iterations': 4, 'batch_size': 8, 'save_interval': 2, 'continueTra': 'False', 'train_stepsIni': 0, 'imageType': 'gray', 'root_weights': '../DCGAN_UNIT_baseline/', 'modelSteps': 3}}\n",
      "self.datasets={'train_a': {'class_name': 'dataset_dcgan'}, 'train_b': {'channels': 3, 'scale': 1.0, 'crop_image_height': 224, 'crop_image_width': 224, 'class_name': 'dataset_imagenet_image', 'root': '/home/images/', 'folder': './data/', 'list_name': 'lists/nameReal.txt'}}\n",
      "<__main__.NetConfig object at 0x7f6b7c4999e8>\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "confi = '../DCGAN_UNIT_baseline/exps/gray2colorFundus.yaml'\n",
    "stream = open(confi,'r')\n",
    "docs = yaml.load_all(stream)\n",
    "class NetConfig(object):\n",
    "    def __init__(self, config):\n",
    "        stream = open(config,'r')\n",
    "        docs = yaml.load_all(stream)\n",
    "        for doc in docs:\n",
    "            for k, v in doc.items():\n",
    "                if k == \"train\":\n",
    "                    for k1, v1 in v.items():\n",
    "                        cmd = \"self.\" + k1 + \"=\" + repr(v1)\n",
    "                        print(cmd)\n",
    "                        exec(cmd)\n",
    "        stream.close()\n",
    "\n",
    "config = NetConfig(confi)  \n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(config.datasets['train_b']['channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.layers import Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "class dcgan_gen:\n",
    "    # __init__ could be considered as the constructor method of the class\n",
    "    def __init__(self, config): # self is the instance. config and numEx are parameters\n",
    "        # Hyperparameters\n",
    "        self.image_width = config.hyperparameters['dcgan']['image_width']\n",
    "        self.image_height = config.hyperparameters['dcgan']['image_height']\n",
    "        self.ModelSteps = config.hyperparameters['dcgan']['modelSteps'] \n",
    "        self.root_weights = config.hyperparameters['dcgan']['root_weights']\n",
    "\n",
    "        self.dim = int(self.image_width / 4)\n",
    "        self.latentVar = 100       # latent variables. DO NOT CHANGE IT\n",
    "        self.lrL2 = 1e-7  # This value controls the regularizer\n",
    "        self.dropout = 0.4\n",
    "        \n",
    "    def generator(self):        \n",
    "\n",
    "        G = Sequential()        \n",
    "        depth = 64+64+64+64\n",
    "        # In: 1000\n",
    "        # Out: dim x dim x depth\n",
    "        G.add(Dense(self.dim*self.dim*depth, input_dim=self.latentVar, kernel_regularizer=regularizers.l2(self.lrL2)))\n",
    "        G.add(BatchNormalization(momentum=0.9))\n",
    "        G.add(Activation('relu'))\n",
    "        G.add(Reshape((self.dim, self.dim, depth)))\n",
    "        G.add(Dropout(self.dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        G.add(UpSampling2D(size=(2, 2)))\n",
    "        G.add(Conv2DTranspose(int(depth/2), 5, padding='same', kernel_regularizer=regularizers.l2(self.lrL2)))\n",
    "        G.add(BatchNormalization(momentum=0.9))\n",
    "        G.add(Activation('relu'))\n",
    "\n",
    "        G.add(UpSampling2D(size=(2, 2)))\n",
    "        G.add(Conv2DTranspose(int(depth/4), 5, padding='same', kernel_regularizer=regularizers.l2(self.lrL2)))\n",
    "        G.add(BatchNormalization(momentum=0.9))\n",
    "        G.add(Activation('relu'))\n",
    "\n",
    "        G.add(Conv2DTranspose(int(depth/8), 5, padding='same', kernel_regularizer=regularizers.l2(self.lrL2)))\n",
    "        G.add(BatchNormalization(momentum=0.9))\n",
    "        G.add(Activation('relu'))\n",
    "\n",
    "        # Out: image_width x image_height x 1 grayscale image [0.0,1.0] per pix\n",
    "        G.add(Conv2DTranspose(1, 5, padding='same', kernel_regularizer=regularizers.l2(self.lrL2)))\n",
    "        G.add(Activation('tanh'))\n",
    "\n",
    "        return G\n",
    "        \n",
    "    def fake_image(self, noise_input): # Each method within a class automatically takes the instance as the first argument\n",
    "                           # The instance and numEx are the only parameters we need in this case\n",
    "                        # numEx is the number of noise samples\n",
    "\n",
    "        G = self.generator()\n",
    "        # We first check if the weights exist\n",
    "        weights_fileG = self.root_weights + 'generator_' + str(self.ModelSteps) + '_steps.h5'\n",
    "        G.load_weights(weights_fileG)\n",
    "\n",
    "        # predict using the noise_input matrix. noise_input matrix contains all the generated samples\n",
    "        image_fake = G.predict(noise_input)       \n",
    "        \n",
    "        return image_fake\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = dcgan_gen(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 100)\n",
      "(248, 248, 1)\n"
     ]
    }
   ],
   "source": [
    "# Here we generate the random samples\n",
    "noise_input = np.random.normal(size=[90000, 100])\n",
    "print(noise_input.shape)\n",
    "f = tg.fake_image(np.array([noise_input[0,:]]))\n",
    "print(f[0,:,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Datagenerator using tensors. I HAVE NO IDEA WHY WE NEED TWO ARRAYS. TARGETS ARE THE LABELS?\n",
    "import torch.utils.data as utils\n",
    "import torch\n",
    "\n",
    "my_x = [np.array([1,2]),np.array([5,6])] # a list of numpy arrays\n",
    "print(len(my_x))\n",
    "my_y = [np.array([3.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "print(len(my_y))\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in my_x]) # transform to torch tensors\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in my_y])\n",
    "\n",
    "my_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "my_dataloader = utils.DataLoader(my_dataset) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " 1  2\n",
      "[torch.FloatTensor of size 1x2]\n",
      ", \n",
      " 3\n",
      "[torch.FloatTensor of size 1x1]\n",
      "]\n",
      "[\n",
      " 5  6\n",
      "[torch.FloatTensor of size 1x2]\n",
      ", \n",
      " 2\n",
      "[torch.FloatTensor of size 1x1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for i in my_dataloader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andresEnv",
   "language": "python",
   "name": "andresenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
